# Website Scraping using Beautiful Soup

This repository contains a Python script implemented in a Jupyter Notebook for scraping information from a website using Beautiful Soup.

## Project Overview

The project focuses on web scraping techniques to extract structured data from a specific webpage and store it in a CSV file. It demonstrates how to use Beautiful Soup, a Python library for parsing HTML and XML documents, to extract relevant information from web pages.

## Project Files

### 1. scraping_project.ipynb

This Jupyter Notebook file (`scraping_project.ipynb`) contains the Python code used for scraping the BTS Wikipedia page (`https://en.wikipedia.org/wiki/BTS`). It extracts information such as the introduction, members, and discography, and saves the data into a CSV file (`bts_wikipedia.csv`).

### 2. bts_wikipedia.csv

The `bts_wikipedia.csv` file is the output generated by the scraping project. It stores the extracted data in a structured format for easy analysis and further processing.

## Objective

- Extract information from a publicly accessible website using web scraping techniques.
- Use Beautiful Soup to parse HTML content and extract specific data elements (e.g., text, lists).
- Save the extracted data into a CSV file for future analysis or integration with other tools.

## How to Use

To run the scraping project locally:

1. Ensure you have Python installed on your system.
2. Install the necessary libraries by running:
3. Open `scraping_project.ipynb` in Jupyter Notebook.
4. Run each cell in the notebook sequentially to execute the scraping code.
5. After execution, you will find `bts_wikipedia.csv` generated in the same directory containing the extracted data.

## Next Steps

- Expand the project to include more web pages or websites for scraping.
- Enhance error handling and robustness to handle various website structures and content changes.
- Explore additional data processing and visualization techniques for the scraped data.

## License

This project is licensed under the MIT License. See the LICENSE file for more details.

---

Feel free to modify and expand upon this project as needed. If you encounter any issues or have questions, please open an issue on GitHub.

